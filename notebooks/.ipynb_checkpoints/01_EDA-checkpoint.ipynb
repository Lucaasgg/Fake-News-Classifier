{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e77cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Exploratory Data Analysis (EDA)\n",
    "#**Dataset:** Fake and Real News  \n",
    "#**Author:** _Lucas Garcia_  \n",
    "#**Date:** _2025-07-04_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae18309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9798fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "DATA_DIR = \"../data/raw\"\n",
    "FAKE_CSV = os.path.join(DATA_DIR, \"Fake.csv\")\n",
    "REAL_CSV = os.path.join(DATA_DIR, \"True.csv\")\n",
    "\n",
    "# Read CSV files\n",
    "fake_df = pd.read_csv(FAKE_CSV)\n",
    "real_df = pd.read_csv(REAL_CSV)\n",
    "\n",
    "# Add label column\n",
    "fake_df['label'] = 'fake'\n",
    "real_df['label'] = 'real'\n",
    "\n",
    "# Concatenate into a single DataFrame\n",
    "df = pd.concat([fake_df, real_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85783a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake shape: (23481, 5)\n",
      "Real shape: (21417, 5)\n",
      "Total shape: (44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date label  \n",
       "0  December 31, 2017  fake  \n",
       "1  December 31, 2017  fake  \n",
       "2  December 30, 2017  fake  \n",
       "3  December 29, 2017  fake  \n",
       "4  December 25, 2017  fake  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect shapes\n",
    "print(\"Fake shape:\", fake_df.shape)\n",
    "print(\"Real shape:\", real_df.shape)\n",
    "print(\"Total shape:\", df.shape)\n",
    "\n",
    "# Display first rows\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values per column\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Count duplicate rows\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {dup_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a55150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count labels\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.title(\"Fake vs Real News Distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length (number of words)\n",
    "df['text_len'] = df['text'].apply(lambda t: len(str(t).split()))\n",
    "\n",
    "# Display descriptive statistics\n",
    "df['text_len'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning: lowercasing, remove punctuation, stopwords, tokenization\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Download resources (si aún no los tienes)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords set and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords & stem\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stop_words]\n",
    "    # Rejoin\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply cleaning to the 'text' column\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Vistazo al resultado\n",
    "df[['text', 'clean_text']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)   # ajusta max_features si quieres\n",
    "X = tfidf.fit_transform(df['clean_text'])\n",
    "y = df['label'].map({'fake':0, 'real':1})    # convierte a 0/1\n",
    "\n",
    "# Split train/validation/test: 70/15/15\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Instantiate and train\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_nb = nb.predict(X_val)\n",
    "\n",
    "# Metrics\n",
    "print(\"Naive Bayes Validation Accuracy:\", accuracy_score(y_val, y_pred_nb))\n",
    "print(\"Naive Bayes Validation F1-score:\", f1_score(y_val, y_pred_nb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56299ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate and train\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "# Metrics\n",
    "print(\"Logistic Regression Validation Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "print(\"Logistic Regression Validation F1-score:\", f1_score(y_val, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed963e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],   # compatible con l1 y l2\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best params:\", grid_lr.best_params_)\n",
    "print(\"Best CV F1-score:\", grid_lr.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0047c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator from grid search\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "# Validation metrics\n",
    "y_val_pred = best_lr.predict(X_val)\n",
    "print(\"Tuned LR Validation F1-score:\", f1_score(y_val, y_val_pred))\n",
    "\n",
    "# Test metrics\n",
    "y_test_pred = best_lr.predict(X_test)\n",
    "print(\"Tuned LR Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Tuned LR Test F1-score:\", f1_score(y_test, y_test_pred))\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00952082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, roc_curve, auc\n",
    "\n",
    "final_model = best_lr  # o rf, o el que elijas\n",
    "\n",
    "# Plot confusion matrix on test set\n",
    "plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                      display_labels=['fake','real'],\n",
    "                      cmap=plt.cm.Blues,\n",
    "                      normalize='true')\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "y_prob = final_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save TF-IDF vectorizer\n",
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.joblib')\n",
    "# Save final model\n",
    "joblib.dump(final_model, '../models/final_fake_news_model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
